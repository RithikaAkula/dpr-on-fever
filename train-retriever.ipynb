{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c196b13c",
   "metadata": {},
   "source": [
    "## GETTING HARD NEGATIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15f0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1543864",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fd2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d6960b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df = pd.read_parquet('processed_df/claim_df.parquet')\n",
    "wiki_df = pd.read_parquet('processed_df/wiki_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e685ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115305\n"
     ]
    }
   ],
   "source": [
    "queries = list(set(claim_df['claim']))\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f80616ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3715301\n"
     ]
    }
   ],
   "source": [
    "passages = list(set(wiki_df['text']))\n",
    "print(len(passages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f76b8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.weight', 'question_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_type = \"dpr\"\n",
    "context_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "query_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "\n",
    "model_args = RetrievalArgs()\n",
    "\n",
    "# Create a TransformerModel\n",
    "model = RetrievalModel(\n",
    "    model_type=model_type,\n",
    "    context_encoder_name=context_name,\n",
    "    query_encoder_name=query_name,\n",
    "    args=model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d71a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet('processed_df/merged_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c380fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = merged_df[['claim', 'wiki_text', 'wiki_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3c6aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102748"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71660209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2719002/144983162.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.rename(columns={'claim': 'query_text', 'wiki_text': 'gold_passage', 'wiki_title': 'title'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data.rename(columns={'claim': 'query_text', 'wiki_text': 'gold_passage', 'wiki_title': 'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf9ea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>gold_passage</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nikolaj coster waldau worked with the fox broa...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nikolaj coster waldau was not in a danish thri...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nikolaj coster waldau worked with peter dinklage</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nikolaj coster waldau refused to ever work wit...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nikolaj coster waldau was in a film</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0  nikolaj coster waldau worked with the fox broa...   \n",
       "1  nikolaj coster waldau was not in a danish thri...   \n",
       "2   nikolaj coster waldau worked with peter dinklage   \n",
       "3  nikolaj coster waldau refused to ever work wit...   \n",
       "4                nikolaj coster waldau was in a film   \n",
       "\n",
       "                                        gold_passage                  title  \n",
       "0  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau  \n",
       "1  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau  \n",
       "2  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau  \n",
       "3  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau  \n",
       "4  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d8cf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = list(train_data['query_text'].tolist())\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9ef1edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages = list(set(train_data['gold_passage'].tolist()))\n",
    "len(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ab135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Preparing prediction passages started\n",
      "INFO:simpletransformers.retrieval.retrieval_utils:Preparing prediction passages completed\n",
      "INFO:simpletransformers.retrieval.retrieval_utils:Generating embeddings for prediction passages started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492e1e92cad94b7cb9365d670dbbd110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Generating embeddings for prediction passages completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23869d2627ac4ff890628f1e1b1fe9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Adding FAISS index to prediction passages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2157d8433b134150aae1514ea76e0ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Adding FAISS index to prediction passages completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60be3a5b62048e397dda1ff95bd0a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating query embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a835cc698b7f42a799fd9ab11f0e8e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving docs:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The hard negatives will be written to the output dir by default.\n",
    "hard_df = model.build_hard_negatives(\n",
    "    queries=queries,\n",
    "    passage_dataset=passages,\n",
    "    retrieve_n_docs=1,\n",
    "#     output_dir = '/home/rahvk/tmp/cache/hard_neg'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6498d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102748"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f56717a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_df.to_parquet('processed_df/hard_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db7d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_df = pd.read_parquet('processed_df/hard_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a0cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102748"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7c9d05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2719002/947600376.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['hard_negative'] = hard_df\n"
     ]
    }
   ],
   "source": [
    "train_data['hard_negative'] = hard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e90bf9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>gold_passage</th>\n",
       "      <th>title</th>\n",
       "      <th>hard_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nikolaj coster waldau worked with the fox broa...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "      <td>frederick fred seibert lrb born september 15 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nikolaj coster waldau was not in a danish thri...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "      <td>lars von trier lrb lars trier 30 april 1956 rr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nikolaj coster waldau worked with peter dinklage</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "      <td>arthur schopenhauer lrb lsb a t o pm ha rsb 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nikolaj coster waldau refused to ever work wit...</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "      <td>harry herbert frazee lrb june 29 1880 june 4 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nikolaj coster waldau was in a film</td>\n",
       "      <td>nikolaj coster waldau lrb lsb ne ola k sd ald ...</td>\n",
       "      <td>Nikolaj_Coster-Waldau</td>\n",
       "      <td>armin mueller stahl lrb born 17 december 1930 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0  nikolaj coster waldau worked with the fox broa...   \n",
       "1  nikolaj coster waldau was not in a danish thri...   \n",
       "2   nikolaj coster waldau worked with peter dinklage   \n",
       "3  nikolaj coster waldau refused to ever work wit...   \n",
       "4                nikolaj coster waldau was in a film   \n",
       "\n",
       "                                        gold_passage                  title  \\\n",
       "0  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau   \n",
       "1  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau   \n",
       "2  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau   \n",
       "3  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau   \n",
       "4  nikolaj coster waldau lrb lsb ne ola k sd ald ...  Nikolaj_Coster-Waldau   \n",
       "\n",
       "                                       hard_negative  \n",
       "0  frederick fred seibert lrb born september 15 1...  \n",
       "1  lars von trier lrb lars trier 30 april 1956 rr...  \n",
       "2  arthur schopenhauer lrb lsb a t o pm ha rsb 22...  \n",
       "3  harry herbert frazee lrb june 29 1880 june 4 1...  \n",
       "4  armin mueller stahl lrb born 17 december 1930 ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aed1fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.weight', 'question_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.retrieval import RetrievalModel\n",
    "\n",
    "\n",
    "model_type = \"dpr\"\n",
    "context_encoder_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "question_encoder_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "\n",
    "model = RetrievalModel(\n",
    "    model_type=model_type,\n",
    "    context_encoder_name=context_encoder_name,\n",
    "    query_encoder_name=question_encoder_name,\n",
    "    hard_negatives=True,\n",
    "    include_title=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14547243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e247d93618ff416da329b3da9fbf9473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92af95297648473193c25fad744abd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add327db67854c52a5c8fd60ea6e91c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b68e22c50514313b7a06e70a5977dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/12844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahvk/data/tmp/anaconda3/envs/faiss_1.7.4/lib/python3.10/site-packages/simpletransformers/retrieval/retrieval_model.py:1659: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (max_idxs == torch.tensor(labels)).sum().cpu().detach().numpy().item()\n",
      "/home/rahvk/data/tmp/anaconda3/envs/faiss_1.7.4/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-2000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-4000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-6000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-8000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-10000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-12000\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into /home/rahvk/data/tmp/cache/model-it/checkpoint-12844-epoch-1\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into outputs/\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of None model complete. Saved to /home/rahvk/data/tmp/cache/model-it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12844, 0.274144477266532)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist=model.train_model(train_data, output_dir='/home/rahvk/data/tmp/cache/model-it', show_running_loss=True, use_cuda=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0104265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step, training_loss = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3453860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Loading evaluation passages to a Huggingface Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92da6598f79b426a854529d461f57d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Loading evaluation passages to a Huggingface Dataset completed.\n",
      "INFO:simpletransformers.retrieval.retrieval_utils:Generating embeddings for evaluation passages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f848d8a03b54efa9c9a650a7ae62524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Generating embeddings for evaluation passages completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639dc2571bc04f67bb0a58f105677b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Adding FAISS index to evaluation passages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fe240896394c6aab3656071721fc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_utils:Adding FAISS index to evaluation passages completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bed03d99564455988b5436c49b8e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cc601e030f464db7a8c9a3643a964d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7144746f4ff04875992f6766896db090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/12844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b8c311c088480a85eec6b313d0bcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving docs:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.retrieval.retrieval_model:{'eval_loss': 8.48934105770011, 'mrr@1': 0.34977809787051817, 'mrr@2': 0.36124304122707984, 'mrr@3': 0.3646105033674622, 'mrr@5': 0.3672037411920427, 'mrr@10': 0.3689218644660599, 'top_1_accuracy': 0.34977809787051817, 'top_2_accuracy': 0.3727079845836415, 'top_3_accuracy': 0.38281037100478843, 'top_5_accuracy': 0.39420718651457937, 'top_10_accuracy': 0.40698602405886247}\n"
     ]
    }
   ],
   "source": [
    "result = model.eval_model(train_data)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4429232",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, doc_ids, doc_vectors, doc_dicts = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc31cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "973c2d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102751, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2c8cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3442., 14938.,  3440.,  3447., 69013.,  3448.,  3443., 14943.,\n",
       "       69021., 14945.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba24e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python faiss_1.7.4",
   "language": "python",
   "name": "faiss_1.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
