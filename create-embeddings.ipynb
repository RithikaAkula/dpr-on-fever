{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08362ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet('processed_df/merged_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278afed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.reset_index()\n",
    "merged_df.rename(columns={'index': 'claim_index'}, inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = merged_df[['claim_index', 'wiki_index', 'wiki_text']].drop_duplicates(subset = ['wiki_index', 'wiki_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = list(merged_df['claim'])\n",
    "wiki_text = list(set(list(merged_df['wiki_text'])))\n",
    "# evidence = list(df['evidence_wiki_url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a522a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e15fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import torch\n",
    "\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-multiset-base').to(device)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-multiset-base')\n",
    "\n",
    "def encode_questions(questions, batch_size=32):\n",
    "    question_encoder.eval()\n",
    "    question_embeddings = []\n",
    "\n",
    "    for start_idx in range(0, len(questions), batch_size):\n",
    "        \n",
    "        print(f\"Encoding indices: {start_idx}:{start_idx+batch_size}\")\n",
    "        batch_questions = questions[start_idx:start_idx + batch_size]\n",
    "\n",
    "        # Using batch_encode_plus for efficient tokenization\n",
    "        inputs = question_tokenizer.batch_encode_plus(batch_questions, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        # Move tokenized inputs to GPU\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass through the encoder\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = question_encoder(**inputs).pooler_output\n",
    "        question_embeddings.append(batch_embeddings.cpu())\n",
    "        \n",
    "        # Clearing memory\n",
    "        del inputs, batch_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(question_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "claims_embeddings = encode_questions(claims, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d91fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-multiset-base').to(device)\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-multiset-base')\n",
    "\n",
    "def encode_contexts(contexts, batch_size=32):\n",
    "    context_encoder.eval()\n",
    "    context_embeddings = []\n",
    "\n",
    "    for start_idx in range(0, len(contexts), batch_size):\n",
    "        \n",
    "        print(f\"Encoding indices: {start_idx}:{start_idx+batch_size}\")\n",
    "        batch_contexts = contexts[start_idx:start_idx + batch_size]\n",
    "\n",
    "        # Using batch_encode_plus for efficient tokenization\n",
    "        inputs = context_tokenizer.batch_encode_plus(batch_contexts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        # Move tokenized inputs to GPU\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass through the encoder\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = context_encoder(**inputs).pooler_output\n",
    "        context_embeddings.append(batch_embeddings.cpu())\n",
    "        \n",
    "        # Clearing memory\n",
    "        del inputs, batch_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(context_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "context_embeddings = encode_contexts(wiki_text, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18315c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4587e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_embeddings = claims_embeddings.to(device)\n",
    "context_embeddings = context_embeddings.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_similarity_in_batches(claims_embeddings, context_embeddings, batch_size=100):\n",
    "    num_claims = claims_embeddings.size(0)\n",
    "    num_contexts = context_embeddings.size(0)\n",
    "    top_passages_indices = np.zeros(num_claims, dtype=int)\n",
    "    \n",
    "    for start_idx in range(0, num_claims, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_claims)\n",
    "        print(f\"Computing from {start_idx} : {end_idx}\")\n",
    "        batch_scores = torch.matmul(claims_embeddings[start_idx:end_idx], context_embeddings.T)\n",
    "\n",
    "        # Compute top passages for the current batch and store the indices\n",
    "        top_passages_batch = np.argmax(batch_scores.detach().cpu().numpy(), axis=1)\n",
    "        \n",
    "        top_passages_indices[start_idx:end_idx] = top_passages_batch\n",
    "        \n",
    "        # Clearing memory\n",
    "        del batch_scores\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return top_passages_indices\n",
    "\n",
    "embeddings = compute_similarity_in_batches(claims_embeddings, context_embeddings, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a950901",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56493584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(embeddings), max(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29184e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[i]['wiki_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, claim in enumerate(claims[:10]):\n",
    "    similar_context_index = embeddings[i]\n",
    "    wiki_passage = wiki_df.iloc[similar_context_index]['wiki_text']\n",
    "\n",
    "    print(f\"Claim: {claim}\")\n",
    "    print(f\"Most similar context: {wiki_passage}\")\n",
    "    print(f\"Actual: {merged_df.iloc[i]['wiki_text']}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Assuming context_embeddings is your PyTorch tensor on the CUDA device\n",
    "# First, move the tensor to the CPU, then convert it to a NumPy array\n",
    "context_embeddings_cpu = context_embeddings.cpu().numpy()\n",
    "\n",
    "# Now you can save it using h5py\n",
    "with h5py.File('embeddings/merged_embeddings.h5', 'w') as file:\n",
    "    file.create_dataset('merged_embeddings', data=context_embeddings_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8503e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python faiss_1.7.4",
   "language": "python",
   "name": "faiss_1.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
